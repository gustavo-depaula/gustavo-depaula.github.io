
@misc{ducoffe_lard_2023,
	title = {{LARD} -- {Landing} {Approach} {Runway} {Detection} -- {Dataset} for {Vision} {Based} {Landing}},
	url = {http://arxiv.org/abs/2304.09938},
	doi = {10.48550/arXiv.2304.09938},
	abstract = {As the interest in autonomous systems continues to grow, one of the major challenges is collecting sufficient and representative real-world data. Despite the strong practical and commercial interest in autonomous landing systems in the aerospace field, there is a lack of open-source datasets of aerial images. To address this issue, we present a dataset-lard-of high-quality aerial images for the task of runway detection during approach and landing phases. Most of the dataset is composed of synthetic images but we also provide manually labelled images from real landing footages, to extend the detection task to a more realistic setting. In addition, we offer the generator which can produce such synthetic front-view images and enables automatic annotation of the runway corners through geometric transformations. This dataset paves the way for further research such as the analysis of dataset quality or the development of models to cope with the detection tasks. Find data, code and more up-to-date information at https://github.com/deel-ai/LARD},
	urldate = {2024-12-13},
	publisher = {arXiv},
	author = {Ducoffe, Mélanie and Carrere, Maxime and Féliers, Léo and Gauffriau, Adrien and Mussot, Vincent and Pagetti, Claire and Sammour, Thierry},
	month = apr,
	year = {2023},
	note = {arXiv:2304.09938 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/Users/gustavo/Zotero/storage/QN2Q2GGR/Ducoffe et al. - 2023 - LARD -- Landing Approach Runway Detection -- Dataset for Vision Based Landing.pdf:application/pdf;Snapshot:/Users/gustavo/Zotero/storage/Y8IPD5NS/2304.html:text/html},
}

@article{chen_image-based_2024,
	title = {An image-based runway detection method for fixed-wing aircraft based on deep neural network},
	volume = {18},
	copyright = {© 2024 The Authors. IET Image Processing published by John Wiley \& Sons Ltd on behalf of The Institution of Engineering and Technology.},
	issn = {1751-9667},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.13087},
	doi = {10.1049/ipr2.13087},
	abstract = {Visual information is important in final approach and landing phases for an approaching aircraft, it presents supplementary source for navigation system, and provides backup guidance when radio navigation fails, or even supports a complete vision-based landing. Relative position and attitude can be solved from the runway features in the image. Traditional runway detection methods have high latency and low accuracy, which is unable to satisfy the requirements for a safe landing. This paper proposes a real-time runway detection model, efficient runway feature extractor (ERFE), based on deep convolutional neural network, generating semantic segmentation and feature lines output. In order to evaluate the model's effectiveness, a benchmark is proposed to calculate the actual error between predicted feature line and ground truth one. A novel runway dataset which is based on pictures from Microsoft Flight Simulator 2020 (FS2020), is also proposed in this paper to train and test the model. The dataset will be released at https://www.kaggle.com/datasets/relufrank/fs2020-runway-dataset. ERFE shows excellent performance in FS2020 dataset, it gives satisfactory results even for real runway images excluded from our dataset.},
	language = {en},
	number = {8},
	urldate = {2024-12-13},
	journal = {IET Image Processing},
	author = {Chen, Mingqiang and Hu, Yuzhou},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/ipr2.13087},
	keywords = {edge detection, image classification, image segmentation, visual databases},
	pages = {1939--1949},
	file = {Full Text PDF:/Users/gustavo/Zotero/storage/7YBGSYR8/Chen and Hu - 2024 - An image-based runway detection method for fixed-wing aircraft based on deep neural network.pdf:application/pdf;Snapshot:/Users/gustavo/Zotero/storage/MXMVGS8N/ipr2.html:text/html},
}

@misc{chen_bars_2023,
	title = {{BARS}: {A} {Benchmark} for {Airport} {Runway} {Segmentation}},
	shorttitle = {{BARS}},
	url = {http://arxiv.org/abs/2210.12922},
	doi = {10.48550/arXiv.2210.12922},
	abstract = {Airport runway segmentation can effectively reduce the accident rate during the landing phase, which has the largest risk of flight accidents. With the rapid development of deep learning (DL), related methods achieve good performance on segmentation tasks and can be well adapted to complex scenes. However, the lack of large-scale, publicly available datasets in this field makes the development of methods based on DL difficult. Therefore, we propose a benchmark for airport runway segmentation, named BARS. Additionally, a semiautomatic annotation pipeline is designed to reduce the annotation workload. BARS has the largest dataset with the richest categories and the only instance annotation in the field. The dataset, which was collected using the X-Plane simulation platform, contains 10,256 images and 30,201 instances with three categories. We evaluate eleven representative instance segmentation methods on BARS and analyze their performance. Based on the characteristic of an airport runway with a regular shape, we propose a plug-and-play smoothing postprocessing module (SPM) and a contour point constraint loss (CPCL) function to smooth segmentation results for mask-based and contour-based methods, respectively. Furthermore, a novel evaluation metric named average smoothness (AS) is developed to measure smoothness. The experiments show that existing instance segmentation methods can achieve prediction results with good performance on BARS. SPM and CPCL can effectively enhance the AS metric while modestly improving accuracy. Our work will be available at https://github.com/c-wenhui/BARS.},
	urldate = {2024-12-14},
	publisher = {arXiv},
	author = {Chen, Wenhui and Zhang, Zhijiang and Yu, Liang and Tai, Yichun},
	month = apr,
	year = {2023},
	note = {arXiv:2210.12922 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Applied Intelligence 2023},
	file = {Preprint PDF:/Users/gustavo/Zotero/storage/B773FYBB/Chen et al. - 2023 - BARS A Benchmark for Airport Runway Segmentation.pdf:application/pdf;Snapshot:/Users/gustavo/Zotero/storage/7SHK7QAK/2210.html:text/html},
}

@article{wang_valnet_2024,
	title = {{VALNet}: {Vision}-{Based} {Autonomous} {Landing} with {Airport} {Runway} {Instance} {Segmentation}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {{VALNet}},
	url = {https://www.mdpi.com/2072-4292/16/12/2161},
	doi = {10.3390/rs16122161},
	abstract = {Visual navigation, characterized by its autonomous capabilities, cost effectiveness, and robust resistance to interference, serves as the foundation for vision-based autonomous landing systems. These systems rely heavily on runway instance segmentation, which accurately divides runway areas and provides precise information for unmanned aerial vehicle (UAV) navigation. However, current research primarily focuses on runway detection but lacks relevant runway instance segmentation datasets. To address this research gap, we created the Runway Landing Dataset (RLD), a benchmark dataset that focuses on runway instance segmentation mainly based on X-Plane. To overcome the challenges of large-scale changes and input image angle differences in runway instance segmentation tasks, we propose a vision-based autonomous landing segmentation network (VALNet) that uses band-pass filters, where a Context Enhancement Module (CEM) guides the model to learn adaptive “band” information through heatmaps, while an Orientation Adaptation Module (OAM) of a triple-channel architecture to fully utilize rotation information enhances the model’s ability to capture input image rotation transformations. Extensive experiments on RLD demonstrate that the new method has significantly improved performance. The visualization results further confirm the effectiveness and interpretability of VALNet in the face of large-scale changes and angle differences. This research not only advances the development of runway instance segmentation but also highlights the potential application value of VALNet in vision-based autonomous landing systems. Additionally, RLD is publicly available.},
	language = {en},
	number = {12},
	urldate = {2024-12-14},
	journal = {Remote Sensing},
	author = {Wang, Qiang and Feng, Wenquan and Zhao, Hongbo and Liu, Binghao and Lyu, Shuchang},
	month = jan,
	year = {2024},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {band-pass filtering, heatmap guided, instance segmentation, vision-based autonomous landing},
	pages = {2161},
	file = {Full Text PDF:/Users/gustavo/Zotero/storage/4ZIUGYLA/Wang et al. - 2024 - VALNet Vision-Based Autonomous Landing with Airport Runway Instance Segmentation.pdf:application/pdf},
}

@inproceedings{akbar_runway_2019,
	title = {Runway {Detection} and {Localization} in {Aerial} {Images} using {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/document/8945889},
	doi = {10.1109/DICTA47822.2019.8945889},
	abstract = {Landing is the most difficult phase of the flight for any airborne platform. Due to lack of efficient systems, there have been numerous landing accidents resulting in the damage of onboard hardware. Vision based systems provides low cost solution to detect landing sites by providing rich textual information. To this end, this research focuses on accurate detection and localization of runways in aerial images with untidy terrains which would consequently help aerial platforms especially Unmanned Aerial Vehicles (commonly referred to as Drones) to detect landing targets (i.e., runways) to aid automatic landing. Most of the prior work regarding runway detection is based on simple image processing algorithms with lot of assumptions and constraints about precise position of runway in a particular image. First part of this research is to develop runway detection algorithm based on state-of-the-art deep learning architectures while the second part is runway localization using both deep learning and non-deep learning based methods. The proposed runway detection approach is two-stage modular where in the first stage the aerial image classification is achieved to find the existence of runway in that particular image. Later, in the second stage, the identified runways are localized using both conventional line detection algorithms and more recent deep learning models. The runway classification has been achieved with an accuracy of around 97\% whereas the runways have been localized with mean Intersection-over-Union (IoU) score of 0.8.},
	urldate = {2024-12-14},
	booktitle = {2019 {Digital} {Image} {Computing}: {Techniques} and {Applications} ({DICTA})},
	author = {Akbar, Javeria and Shahzad, Muhammad and Malik, Muhammad Imran and Ul-Hasan, Adnan and Shafait, Fasial},
	month = dec,
	year = {2019},
	keywords = {Airports, deep learning, Deep learning, detection, Feature extraction, Image edge detection, localization, runway, Training, Transforms},
	pages = {1--8},
	file = {Full Text PDF:/Users/gustavo/Zotero/storage/4DJKFW2V/Akbar et al. - 2019 - Runway Detection and Localization in Aerial Images using Deep Learning.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/gustavo/Zotero/storage/P3TJEMES/8945889.html:text/html},
}

@misc{yang_diffusion_2024,
	title = {Diffusion {Models}: {A} {Comprehensive} {Survey} of {Methods} and {Applications}},
	shorttitle = {Diffusion {Models}},
	url = {http://arxiv.org/abs/2209.00796},
	doi = {10.48550/arXiv.2209.00796},
	abstract = {Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language generation, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.},
	urldate = {2024-12-14},
	publisher = {arXiv},
	author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
	month = dec,
	year = {2024},
	note = {arXiv:2209.00796 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: 58 pages, 19 figures, citing 389 (up-to-date) papers, project: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy, accepted by ACM Computing Surveys},
	file = {Preprint PDF:/Users/gustavo/Zotero/storage/SDWEEU8J/Yang et al. - 2024 - Diffusion Models A Comprehensive Survey of Methods and Applications.pdf:application/pdf;Snapshot:/Users/gustavo/Zotero/storage/TULNG75V/2209.html:text/html},
}

@inproceedings{ho_denoising_2020,
	title = {Denoising {Diffusion} {Probabilistic} {Models}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
	abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
	urldate = {2024-12-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	year = {2020},
	pages = {6840--6851},
	file = {Full Text PDF:/Users/gustavo/Zotero/storage/3RW6MBTY/Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf:application/pdf},
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2024-12-15},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv:1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: conditionally accepted at MICCAI 2015},
	file = {Preprint PDF:/Users/gustavo/Zotero/storage/ZCWKYC5G/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:application/pdf;Snapshot:/Users/gustavo/Zotero/storage/YA3IB4YG/1505.html:text/html},
}
